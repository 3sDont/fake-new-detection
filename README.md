# fake-new-detection
### **1. Tá»•ng quan Äá»“ Ã¡n**

Äá»“ Ã¡n nÃ y táº­p trung vÃ o viá»‡c xÃ¢y dá»±ng vÃ  Ä‘Ã¡nh giÃ¡ má»™t pipeline hoÃ n chá»‰nh Ä‘á»ƒ phÃ¡t hiá»‡n tin tá»©c giáº£ máº¡o (Fake News Detection) báº±ng cÃ¡ch sá»­ dá»¥ng cÃ¡c kiáº¿n trÃºc Transformer . Há»‡ thá»‘ng Ä‘Æ°á»£c thiáº¿t káº¿ theo hÆ°á»›ng module hÃ³a, bao gá»“m cÃ¡c giai Ä‘oáº¡n tá»« thu tháº­p, khÃ¡m phÃ¡ dá»¯ liá»‡u, tiá»n xá»­ lÃ½, huáº¥n luyá»‡n cho Ä‘áº¿n Ä‘Ã¡nh giÃ¡ mÃ´ hÃ¬nh. Ba mÃ´ hÃ¬nh Transformer tiÃªu biá»ƒu Ä‘Ã£ Ä‘Æ°á»£c lá»±a chá»n Ä‘á»ƒ so sÃ¡nh hiá»‡u suáº¥t: **BERT (bert-base-uncased)**, **RoBERTa (roberta-base)**, vÃ  **XLNet (xlnet-base-cased)**.

Káº¿t quáº£ thá»±c nghiá»‡m cho tháº¥y **RoBERTa** lÃ  mÃ´ hÃ¬nh Ä‘áº¡t hiá»‡u suáº¥t cao nháº¥t vá»›i F1-score lÃªn Ä‘áº¿n **99.81%** trÃªn táº­p kiá»ƒm thá»­. **BERT** cÅ©ng cho tháº¥y hiá»‡u quáº£ máº¡nh máº½ vÃ  á»•n Ä‘á»‹nh vá»›i F1-score lÃ  **99.18%**. **XLNet** máº·c dÃ¹ cÃ³ tiá»m nÄƒng nhÆ°ng gáº·p pháº£i váº¥n Ä‘á» overfitting sá»›m.

### **2. Má»¥c tiÃªu Äá»“ Ã¡n**

1.  **XÃ¢y dá»±ng má»™t pipeline NLP hoÃ n chá»‰nh**, cÃ³ kháº£ nÄƒng tÃ¡i sá»­ dá»¥ng vÃ  má»Ÿ rá»™ng cho bÃ i toÃ¡n phÃ¢n loáº¡i vÄƒn báº£n.
2.  **á»¨ng dá»¥ng vÃ  so sÃ¡nh hiá»‡u suáº¥t** cá»§a ba mÃ´ hÃ¬nh Transformer phá»• biáº¿n (BERT, RoBERTa, XLNet) trÃªn bÃ i toÃ¡n phÃ¡t hiá»‡n tin giáº£.
3.  **ÄÃ¡nh giÃ¡ cÃ¡c mÃ´ hÃ¬nh** má»™t cÃ¡ch toÃ n diá»‡n dá»±a trÃªn cÃ¡c chá»‰ sá»‘ Ä‘o lÆ°á»ng tiÃªu chuáº©n (Accuracy, Precision, Recall, F1-score) vÃ  Ä‘Æ°a ra káº¿t luáº­n vá» mÃ´ hÃ¬nh phÃ¹ há»£p nháº¥t.
4.  **Cung cáº¥p má»™t há»‡ thá»‘ng cÃ³ kháº£ nÄƒng dá»± Ä‘oÃ¡n** nhÃ£n (Tháº­t/Giáº£) cho má»™t vÄƒn báº£n tin tá»©c má»›i.

### **3. Dá»¯ liá»‡u vÃ  PhÃ¢n tÃ­ch KhÃ¡m phÃ¡ (EDA)**

#### **3.1. Nguá»“n vÃ  Äáº·c Ä‘iá»ƒm Dá»¯ liá»‡u**
-   **PhÃ¢n tÃ­ch ban Ä‘áº§u (EDA):**
    -   **Chart:**
        - ![image-4.png](attachment:image-4.png)
        - ![image-5.png](attachment:image-5.png)
        - ![image-6.png](attachment:image-6.png)
        - ![image-7.png](attachment:image-7.png)

    *   **Sá»‘ lÆ°á»£ng:** ~78,617 máº«u tin tá»©c.
    *   **PhÃ¢n phá»‘i nhÃ£n:** Dá»¯ liá»‡u khÃ¡ cÃ¢n báº±ng (44.5% tin tháº­t, 55.5% tin giáº£), giÃºp trÃ¡nh cÃ¡c váº¥n Ä‘á» vá» thiÃªn vá»‹ trong quÃ¡ trÃ¬nh huáº¥n luyá»‡n.
    *   **Dá»¯ liá»‡u thiáº¿u:** CÃ³ 29 giÃ¡ trá»‹ `null` trong cá»™t `text`, Ä‘Æ°á»£c xá»­ lÃ½ á»Ÿ bÆ°á»›c tiá»n xá»­ lÃ½.
    *   **Äá»™ dÃ i vÄƒn báº£n:** PhÃ¢n phá»‘i Ä‘á»™ dÃ i cho tháº¥y pháº§n lá»›n cÃ¡c bÃ i bÃ¡o cÃ³ Ä‘á»™ dÃ i dÆ°á»›i 1000 tá»«, nhÆ°ng cÃ³ má»™t sá»‘ bÃ i ráº¥t dÃ i . Quyáº¿t Ä‘á»‹nh truncate vÄƒn báº£n á»Ÿ Ä‘á»™ dÃ i 512 tokens Ä‘á»ƒ phÃ¹ há»£p vá»›i kiáº¿n trÃºc cá»§a cÃ¡c mÃ´ hÃ¬nh Transformer.
    *   **Word Cloud & N-grams:** PhÃ¢n tÃ­ch tá»« khÃ³a vÃ  cá»¥m tá»« cho tháº¥y sá»± khÃ¡c biá»‡t rÃµ rá»‡t giá»¯a hai loáº¡i tin giáº£ vÃ  tháº­t:
        *   **Tin giáº£:** ThÆ°á»ng xoay quanh cÃ¡c chá»§ Ä‘á» chÃ­nh trá»‹ gÃ¢y tranh cÃ£i vÃ  tÃªn cÃ¡c chÃ­nh trá»‹ gia ná»•i tiáº¿ng nhÆ° "Trump", "Clinton", "Obama". Cá»¥m tá»« "Donald Trump" xuáº¥t hiá»‡n nhiá»u nháº¥t.
        *   **Tin tháº­t:** Sá»­ dá»¥ng cÃ¡c thuáº­t ngá»¯ chÃ­nh thá»‘ng vÃ  cÃ³ tÃ­nh thá»ƒ cháº¿ hÆ¡n nhÆ° "government", "state", "Republican", "House".

Nhá»¯ng phÃ¢n tÃ­ch nÃ y khÃ´ng chá»‰ giÃºp hiá»ƒu rÃµ dá»¯ liá»‡u mÃ  cÃ²n cung cáº¥p cÆ¡ sá»Ÿ Ä‘á»ƒ Ä‘Æ°a ra cÃ¡c quyáº¿t Ä‘á»‹nh trong giai Ä‘oáº¡n tiá»n xá»­ lÃ½ vÃ  xÃ¢y dá»±ng mÃ´ hÃ¬nh.

### **4. Thiáº¿t káº¿ Pipeline vÃ  Kiáº¿n trÃºc Há»‡ thá»‘ng**

Pipeline Ä‘Æ°á»£c thiáº¿t káº¿ theo cÃ¡c module Ä‘á»™c láº­p, má»—i module lÃ  má»™t lá»›p (class) Ä‘áº£m nhiá»‡m má»™t chá»©c nÄƒng cá»¥ thá»ƒ, giÃºp dá»… dÃ ng quáº£n lÃ½ vÃ  tÃ¡i sá»­ dá»¥ng.

| Lá»›p (Class) | Chá»©c nÄƒng | Chi tiáº¿t |
| :--- | :--- | :--- |
| **`KaggleDataLoader`** | Táº£i vÃ  há»£p nháº¥t dá»¯ liá»‡u | TÆ°Æ¡ng tÃ¡c vá»›i `kagglehub` API, Ä‘á»c 2 file CSV, gÃ¡n nhÃ£n `1` (Tháº­t) vÃ  `0` (Giáº£), sau Ä‘Ã³ gá»™p thÃ nh má»™t DataFrame duy nháº¥t. |
| **`EDAVisualizer`** | PhÃ¢n tÃ­ch vÃ  trá»±c quan hÃ³a | Kiá»ƒm tra dá»¯ liá»‡u thiáº¿u/trÃ¹ng láº·p, thá»‘ng kÃª mÃ´ táº£, váº½ biá»ƒu Ä‘á»“ phÃ¢n phá»‘i nhÃ£n, Ä‘á»™ dÃ i vÄƒn báº£n, Word Cloud, vÃ  N-grams. |
| **`DataPreprocessor`** | LÃ m sáº¡ch dá»¯ liá»‡u | Loáº¡i bá» cÃ¡c dÃ²ng `null` vÃ  cÃ¡c cá»™t khÃ´ng cáº§n thiáº¿t, Ä‘áº£m báº£o dá»¯ liá»‡u Ä‘áº§u vÃ o cho mÃ´ hÃ¬nh lÃ  sáº¡ch vÃ  nháº¥t quÃ¡n. |
| **`TextDatasetBuilder`** | Tokenization vÃ  táº¡o Dataset | - Chia dá»¯ liá»‡u thÃ nh cÃ¡c táº­p Train/Val/Test (80-10-10).<br>- Sá»­ dá»¥ng `AutoTokenizer` Ä‘á»ƒ chuyá»ƒn vÄƒn báº£n thÃ nh cÃ¡c token ID phÃ¹ há»£p vá»›i tá»«ng mÃ´ hÃ¬nh.<br>- Táº¡o Ä‘á»‘i tÆ°á»£ng `DatasetDict` cá»§a Hugging Face, tá»‘i Æ°u cho `Trainer` API. |
| **`ModelBuilder`** | Táº£i mÃ´ hÃ¬nh pre-trained | Táº£i mÃ´ hÃ¬nh `AutoModelForSequenceClassification` tá»« Hugging Face Hub vá»›i `num_labels=2` . |
| **`ModelTrainer`** | Cáº¥u hÃ¬nh vÃ  Huáº¥n luyá»‡n | - ÄÃ³ng gÃ³i mÃ´ hÃ¬nh, dá»¯ liá»‡u, vÃ  cÃ¡c tham sá»‘ huáº¥n luyá»‡n vÃ o `Trainer` API.<br>- Cáº¥u hÃ¬nh `TrainingArguments` (learning rate, batch size, epochs, early stopping).<br>- TÃ­ch há»£p `wandb` Ä‘á»ƒ theo dÃµi quÃ¡ trÃ¬nh huáº¥n luyá»‡n. |
| **`ModelEvaluator`** | ÄÃ¡nh giÃ¡ hiá»‡u suáº¥t | Sá»­ dá»¥ng mÃ´ hÃ¬nh Ä‘Ã£ huáº¥n luyá»‡n Ä‘á»ƒ dá»± Ä‘oÃ¡n trÃªn táº­p Test. TÃ­nh toÃ¡n vÃ  hiá»ƒn thá»‹ `classification_report` vÃ  `confusion_matrix`. |
| **`FakeNewsPipelineManager`** | Quáº£n lÃ½ toÃ n bá»™ pipeline | Lá»›p Ä‘iá»u phá»‘i chÃ­nh, gá»i tuáº§n tá»± cÃ¡c module trÃªn Ä‘á»ƒ thá»±c thi toÃ n bá»™ quy trÃ¬nh tá»« Ä‘áº§u Ä‘áº¿n cuá»‘i má»™t cÃ¡ch tá»± Ä‘á»™ng. |

### **5. Quy trÃ¬nh Huáº¥n luyá»‡n vÃ  ÄÃ¡nh giÃ¡**
#### **5.1. Cáº¥u hÃ¬nh Huáº¥n luyá»‡n**
##### **a. CÃ¡c SiÃªu tham sá»‘ Huáº¥n luyá»‡n CÆ¡ báº£n:**
-   **`num_train_epochs=10`**: Sá»‘ vÃ²ng láº·p (epoch) tá»‘i Ä‘a Ä‘á»ƒ huáº¥n luyá»‡n.
-   **`per_device_train_batch_size=32`**: KÃ­ch thÆ°á»›c lÃ´ dá»¯ liá»‡u cho quÃ¡ trÃ¬nh huáº¥n luyá»‡n.
-   **`learning_rate=5e-5`**: Tá»‘c Ä‘á»™ há»c, má»™t giÃ¡ trá»‹ tiÃªu chuáº©n cho viá»‡c fine-tuning cÃ¡c mÃ´ hÃ¬nh Transformer.
-   **`weight_decay=0.01`**: Há»‡ sá»‘ suy giáº£m trá»ng sá»‘ Ä‘á»ƒ giÃºp giáº£m thiá»ƒu overfitting.
##### **b. CÃ¡c Tham sá»‘ Äáº·c biá»‡t vÃ  Chiáº¿n lÆ°á»£c Tá»‘i Æ°u:**
ÄÃ¢y lÃ  cÃ¡c thiáº¿t láº­p nÃ¢ng cao nháº±m tÄƒng hiá»‡u quáº£ vÃ  cháº¥t lÆ°á»£ng cá»§a quÃ¡ trÃ¬nh huáº¥n luyá»‡n:
-   **`fp16=True` (Huáº¥n luyá»‡n Mixed-Precision):** Sá»­ dá»¥ng Ä‘á»™ chÃ­nh xÃ¡c 16-bit Ä‘á»ƒ **tÄƒng tá»‘c Ä‘á»™ huáº¥n luyá»‡n** vÃ  **giáº£m bá»™ nhá»› GPU** sá»­ dá»¥ng.
-   **`load_best_model_at_end=True` & `metric_for_best_model="f1"`:** Äáº£m báº£o mÃ´ hÃ¬nh cuá»‘i cÃ¹ng Ä‘Æ°á»£c chá»n lÃ  checkpoint cÃ³ **F1-score cao nháº¥t** trÃªn táº­p validation, giÃºp chá»n ra phiÃªn báº£n tá»‘t nháº¥t thay vÃ¬ phiÃªn báº£n cuá»‘i cÃ¹ng.
-   **`callbacks=[EarlyStoppingCallback(early_stopping_patience=2)]`:** Tá»± Ä‘á»™ng **dá»«ng huáº¥n luyá»‡n sá»›m** náº¿u F1-score khÃ´ng cáº£i thiá»‡n sau 2 epoch, giÃºp **ngÄƒn cháº·n overfitting** vÃ  tiáº¿t kiá»‡m tÃ i nguyÃªn tÃ­nh toÃ¡n.
-   **`report_to="wandb"`:** TÃ­ch há»£p vá»›i **Weights & Biases** Ä‘á»ƒ **theo dÃµi vÃ  trá»±c quan hÃ³a** toÃ n bá»™ quÃ¡ trÃ¬nh huáº¥n luyá»‡n, giÃºp dá»… dÃ ng phÃ¢n tÃ­ch vÃ  so sÃ¡nh káº¿t quáº£.

#### **5.2. Báº£ng tá»•ng há»£p káº¿t quáº£**

| MÃ´ hÃ¬nh | Accuracy | Precision | Recall | F1-Score | Best Epoch |
| :--- | :--- | :--- | :--- | :--- | :--- |
| **RoBERTa** | 99.83% | 99.80% | 99.83% | **99.81%** | Epoch 10 |
| **BERT** | 99.35% | 99.45% | 99.13% | **99.18%** | Epoch 5 |
| **XLNet** | 98.51% | 98.87% | 97.77% | **98.32%** | Epoch 1 |

*Ghi chÃº: XLNet dá»«ng sá»›m á»Ÿ Epoch 3 do overfitting, mÃ´ hÃ¬nh tá»‘t nháº¥t Ä‘Æ°á»£c ghi nháº­n á»Ÿ Epoch 1.*

#### **5.3. Tháº£o luáº­n Káº¿t quáº£**

1.  **RoBERTa (roberta-base):**
    -   **Káº¿t quáº£ vÃ  Ä‘á»“ thá»‹:**
    - ![image-9.png](attachment:image-9.png)
        - Äá»™ chÃ­nh xÃ¡c (Accuracy) vÃ  F1-Score: Cáº£ hai chá»‰ sá»‘ nÃ y Ä‘á»u Ä‘áº¡t **1.00** tÆ°Æ¡ng Ä‘Æ°Æ¡ng vá»›i **100%**. Äiá»u nÃ y cho tháº¥y mÃ´ hÃ¬nh cÃ³ kháº£ nÄƒng phÃ¢n loáº¡i cá»±c ká»³ chÃ­nh xÃ¡c vÃ  Ä‘áº¡t Ä‘Æ°á»£c sá»± cÃ¢n báº±ng tuyá»‡t Ä‘á»‘i giá»¯a Precision vÃ  Recall.
    -   **Hiá»‡u suáº¥t:** VÆ°á»£t trá»™i nháº¥t vá»›i F1-score **99.81%**. MÃ´ hÃ¬nh thá»ƒ hiá»‡n kháº£ nÄƒng náº¯m báº¯t ngá»¯ cáº£nh sÃ¢u vÃ  cÃ¡c sáº¯c thÃ¡i ngÃ´n ngá»¯ tinh vi, giÃºp phÃ¢n biá»‡t tin tháº­t vÃ  giáº£ má»™t cÃ¡ch chÃ­nh xÃ¡c.
    -   **Thá»i gian:** Máº·c dÃ¹ máº¥t nhiá»u thá»i gian nháº¥t, nhÆ°ng hiá»‡u suáº¥t Ä‘áº¡t Ä‘Æ°á»£c hoÃ n toÃ n xá»©ng Ä‘Ã¡ng.

2.  **BERT (bert-base-uncased):**
    -   **Káº¿t quáº£ vÃ  Ä‘á»“ thá»‹:**
    - ![image-8.png](attachment:image-8.png)
        - Äá»™ chÃ­nh xÃ¡c vÃ  F1-score tá»•ng thá»ƒ ráº¥t cao (99%).
        - Kháº£ nÄƒng nháº­n diá»‡n tin giáº£ gáº§n nhÆ° tuyá»‡t Ä‘á»‘i (Recall = 1.00), giÃºp giáº£m thiá»ƒu tá»‘i Ä‘a viá»‡c bá» sÃ³t tin tá»©c sai lá»‡ch.
    
    -   **Hiá»‡u suáº¥t:** Äáº¡t F1-score **99.18%**, chá»©ng tá» sá»©c máº¡nh cá»§a kiáº¿n trÃºc Transformer gá»‘c. BERT lÃ  má»™t lá»±a chá»n ráº¥t tá»‘t, cÃ¢n báº±ng giá»¯a hiá»‡u suáº¥t cao vÃ  thá»i gian huáº¥n luyá»‡n há»£p lÃ½.
    -   **Early Stopping:** MÃ´ hÃ¬nh Ä‘áº¡t hiá»‡u suáº¥t tá»‘t nháº¥t á»Ÿ epoch thá»© 5 vÃ  dá»«ng sá»›m á»Ÿ epoch thá»© 7, cho tháº¥y nÃ³ há»™i tá»¥ nhanh hÆ¡n RoBERTa.


3.  **XLNet (xlnet-base-cased):**
    -   **Káº¿t quáº£ vÃ  Ä‘á»“ thá»‹:**
    - ![image-10.png](attachment:image-10.png)
        - Äá»™ chÃ­nh xÃ¡c (Accuracy) vÃ  F1-Score: CÃ¡c chá»‰ sá»‘ nÃ y Ä‘á»u Ä‘áº¡t 99%. Tuy nhiÃªn, cáº§n lÆ°u Ã½ ráº±ng Ä‘Ã¢y lÃ  káº¿t quáº£ cá»§a mÃ´ hÃ¬nh táº¡i epoch Ä‘áº§u tiÃªn, lÃ  epoch cÃ³ hiá»‡u suáº¥t tá»‘t nháº¥t trÆ°á»›c khi mÃ´ hÃ¬nh báº¯t Ä‘áº§u overfitting.
    -   **Hiá»‡u suáº¥t:** Äáº¡t F1-score tá»‘t nháº¥t lÃ  **98.32%** á»Ÿ epoch Ä‘áº§u tiÃªn. Tuy nhiÃªn, hiá»‡u suáº¥t giáº£m máº¡nh á»Ÿ cÃ¡c epoch sau do **overfitting**.
    -   **Early Stopping:** CÆ¡ cháº¿ dá»«ng sá»›m Ä‘Ã£ Ä‘Æ°á»£c kÃ­ch hoáº¡t á»Ÿ epoch thá»© 3, cho tháº¥y mÃ´ hÃ¬nh nÃ y ráº¥t nháº¡y cáº£m vá»›i dá»¯ liá»‡u vÃ  cáº§n cÃ¡c ká»¹ thuáº­t Ä‘iá»u chuáº©n (regularization) máº¡nh hÆ¡n hoáº·c tinh chá»‰nh siÃªu tham sá»‘ ká»¹ lÆ°á»¡ng hÆ¡n.

#### **5.4. Káº¿t quáº£ Dá»± Ä‘oÃ¡n (Inference)**
ğŸ“° "NASA confirms presence of microbial life on Europa." â†’ Dá»± Ä‘oÃ¡n: FAKE

ğŸ“° "Bill Gates to implant tracking chips via vaccines, claims viral post." â†’ Dá»± Ä‘oÃ¡n: FAKE

ğŸ“° "Biden signs executive order on AI regulation." â†’ Dá»± Ä‘oÃ¡n: FAKE

ğŸ“° "Apple releases new iPhone model with brainwave control." â†’ Dá»± Ä‘oÃ¡n: FAKE

ğŸ“° "WHO warns of new COVID variant emerging in Southeast Asia." â†’ Dá»± Ä‘oÃ¡n: FAKE

CÃ¡c mÃ´ hÃ¬nh Ä‘á»u dá»± Ä‘oÃ¡n chÃ­nh xÃ¡c cáº£ 5 cÃ¢u máº«u lÃ  **FAKE**. Äiá»u nÃ y cho tháº¥y cÃ¡c mÃ´ hÃ¬nh Ä‘Ã£ há»c Ä‘Æ°á»£c cÃ¡c Ä‘áº·c trÆ°ng cá»‘t lÃµi cá»§a tin giáº£ (thÆ°á»ng lÃ  cÃ¡c thÃ´ng tin giáº­t gÃ¢n, khÃ³ tin) vÃ  khÃ´ng bá»‹ áº£nh hÆ°á»Ÿng bá»Ÿi sá»± xuáº¥t hiá»‡n cá»§a cÃ¡c thá»±c thá»ƒ uy tÃ­n (NASA, WHO, Bill Gates), chá»©ng tá» tÃ­nh tá»•ng quÃ¡t hÃ³a cao.

### **6. Káº¿t luáº­n**

ThÃ nh cÃ´ng trong viá»‡c xÃ¢y dá»±ng má»™t pipeline NLP máº¡nh máº½, cÃ³ cáº¥u trÃºc tá»‘t vÃ  Ä‘áº¡t Ä‘Æ°á»£c káº¿t quáº£ tá»‘t trÃªn bÃ i toÃ¡n phÃ¡t hiá»‡n tin giáº£.

-   **MÃ´ hÃ¬nh tá»‘t nháº¥t:** **RoBERTa** lÃ  mÃ´ hÃ¬nh chiáº¿n tháº¯ng vá» máº·t hiá»‡u suáº¥t, phÃ¹ há»£p cho cÃ¡c á»©ng dá»¥ng Ä‘Ã²i há»i Ä‘á»™ chÃ­nh xÃ¡c cao nháº¥t.
-   **Lá»±a chá»n thá»±c táº¿:** **BERT** lÃ  má»™t lá»±a chá»n thá»±c táº¿ vÃ  cÃ¢n báº±ng, cho hiá»‡u suáº¥t ráº¥t tá»‘t vá»›i thá»i gian huáº¥n luyá»‡n ngáº¯n hÆ¡n.
-   **BÃ i há»c tá»« XLNet:** Cáº§n cáº©n trá»ng vá»›i hiá»‡n tÆ°á»£ng overfitting khi lÃ m viá»‡c vá»›i cÃ¡c mÃ´ hÃ¬nh phá»©c táº¡p vÃ  cáº§n Ã¡p dá»¥ng cÃ¡c cÆ¡ cháº¿ Ä‘iá»u chuáº©n phÃ¹ há»£p.

### **7. HÆ°á»›ng phÃ¡t triá»ƒn trong TÆ°Æ¡ng lai**

-   **Má»Ÿ rá»™ng mÃ´ hÃ¬nh vÃ  fine-tuning chuyÃªn sÃ¢u:**
    -   Thá»­ nghiá»‡m vá»›i cÃ¡c mÃ´ hÃ¬nh lá»›n hÆ¡n vÃ  tiÃªn tiáº¿n hÆ¡n nhÆ° `DeBERTa`, `Longformer`, `RoBERTa-large`,...
    -   Ãp dá»¥ng cÃ¡c ká»¹ thuáº­t fine-tuning nÃ¢ng cao nhÆ° gradual unfreezing hoáº·c layer-wise learning rate decay.
-   **Cáº£i thiá»‡n dá»¯ liá»‡u:**
    -   Thu tháº­p thÃªm dá»¯ liá»‡u Ä‘a dáº¡ng hÆ¡n tá»« nhiá»u nguá»“n vÃ  nhiá»u lÄ©nh vá»±c (kinh táº¿, y táº¿, cÃ´ng nghá»‡) Ä‘á»ƒ tÄƒng tÃ­nh tá»•ng quÃ¡t cá»§a mÃ´ hÃ¬nh.
    -   Má»Ÿ rá»™ng sang dá»¯ liá»‡u Ä‘a ngÃ´n ngá»¯ (vÃ­ dá»¥: tiáº¿ng Viá»‡t).
-   **Tá»‘i Æ°u hÃ³a vÃ  Triá»ƒn khai:**
    -   Sá»­ dá»¥ng cÃ¡c ká»¹ thuáº­t nhÆ° quantization, pruning Ä‘á»ƒ tá»‘i Æ°u hÃ³a mÃ´ hÃ¬nh cho viá»‡c triá»ƒn khai.
    -   XÃ¢y dá»±ng má»™t á»©ng dá»¥ng web/mobile Ä‘Æ¡n giáº£n Ä‘á»ƒ ngÆ°á»i dÃ¹ng cÃ³ thá»ƒ trá»±c tiáº¿p kiá»ƒm tra tin tá»©c.
-   **NÃ¢ng cao tÃ­nh giáº£i thÃ­ch :**
    -   TÃ­ch há»£p cÃ¡c cÃ´ng cá»¥ nhÆ° LIME hoáº·c SHAP Ä‘á»ƒ giáº£i thÃ­ch lÃ½ do táº¡i sao má»™t vÄƒn báº£n Ä‘Æ°á»£c phÃ¢n loáº¡i lÃ  tháº­t/giáº£, giÃºp tÄƒng Ä‘á»™ tin cáº­y cá»§a há»‡ thá»‘ng.
-   **ÄÃ¡nh giÃ¡ mÃ´ hÃ¬nh theo chiá»u sÃ¢u: DÃ¹ng thÃªm cÃ¡c chá»‰ sá»‘ ngoÃ i F1 nhÆ° MCC hoáº·c AUROC.**
